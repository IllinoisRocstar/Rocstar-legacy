<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.7"/>
<title>Rocstar: How To Set Up Testing for an IR Project</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen_html_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="IRTriangles_small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">Rocstar
   &#160;<span id="projectnumber">1.0</span>
   </div>
   <div id="projectbrief">Rocstar multiphysics simulation application</div>
  </td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.7 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('testingproject_guide.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(12)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">How To Set Up Testing for an <a class="el" href="namespaceIR.html">IR</a> Project </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="testing_intro"></a>
Introduction</h1>
<p>Testing is part of the <a class="el" href="namespaceIR.html">IR</a> development process. It is very important that we have a consistent, integrated testing in our codes. General guidelines:</p><ul>
<li>We use CMake/CTest/CDash for our test driving substrate</li>
<li>Project unit testing should be centralized/encapsulated in a few constructs</li>
<li>All applications should return 0 to indicate no errors, or passed test, and non-zero otherwise.</li>
<li>Project tests should be integrated through CMake so that the user can use "make test" to run them</li>
</ul>
<h1><a class="anchor" id="testing_constructs_sec"></a>
Testing with IRAD</h1>
<p>IRAD offers facilities designed to assist with code and program testing. IRAD's testing framework supports serial, and parallel tests, platform specific tests, and complex behavior tests. IRAD's testing facilities come in the form of coding constructs and utility programs. Both are described below. </p>
<h2><a class="anchor" id="irad_testing_code"></a>
IRAD Testing Constructs</h2>
<p>IRAD offers the following code constructs for implementing testing in project codes:</p><ul>
<li>IRAD::Util::TestResults</li>
<li>IRAD::Util::TestingObject</li>
</ul>
<p>In general, project-specific testing objects can inherit from the IRAD::Util::TestingObject and implement their own tests as member functions of this derived class. The member methods take an object of type IRAD::Util::TestResults (or one that inherits from this class), and populate it with testing results. The results object can be streamed - and so typically these results can be streamed to the screen, to a file, or string for further processing.</p>
<p>The IRAD testing code constructs are defined in <code>IRAD/include/Testing.H</code> and an example of their use can be found in the IRAD::Util::TestObject class. This object implements all the tests for the IRAD::Util namespace, and is driven by the IRAD::Util::UtilTest function. In other words, the IRAD::Util::UtilTest function implements a command line interface for the IRAD::Util::TestObject, which implements all the existing tests for the IRAD::Util namespace.</p>
<p>More extensive use of the IRAD code constructs for testing can be found in the example testing objects for GridConversion, which are implemented in <a class="el" href="classGridConversion_1_1TestingObject.html" title="Project-specific testing object. ">GridConversion::TestingObject</a> and GridConversion::ParallelTestingObject. These testing objects use simple test fixture functions from the <a class="el" href="namespaceGridConversion_1_1TestFixture.html" title="Namespace for storing simple test utility fixtures. ">GridConversion::TestFixture</a> namespace and are driven by <a class="el" href="namespaceGridConversion.html#a0449cb27fdca26e21a0be394f2ae38a2" title="Drives the GridConversion::TestObject. ">GridConversion::Test</a> and <a class="el" href="namespaceGridConversion.html#ad06df63ea71c2a866efb3ff9c90d7190" title="Drives the GridConversion::TestObject. ">GridConversion::ParallelTest</a>, respectively.</p>
<dl class="section note"><dt>Note</dt><dd>A major advantage of encapsulating all tests in a single object is that external entities need only to instantiate your project-specific testing object to get access to the project's tests. This greatly reduces the complexity of rolling integrated software products out of code from multiple projects.</dd></dl>
<h2><a class="anchor" id="irad_testing_util"></a>
IRAD Testing Support Utilities</h2>
<p>IRAD also offers a couple of utilities to support the running of tests. These utilities and their documentation are:</p><ul>
<li><em>runtest</em> (IRAD::RunTest)</li>
<li><em>testresults</em> (IRAD::TestResults)</li>
</ul>
<h3>Running complex tests with <em>runtest</em>.</h3>
<p>The <em>runtest</em> utility is designed to be called from the project's CMakeLists.txt cmake configuration file. Its purpose is to run scripted tests where the complexity or platform-dependent nature of the test being run precludes its being run as a simple test. The <em>runtest</em> utility can run a single named executable, a list of test from file, or resolve platform-specific tests.</p>
<p>Examples of how to use the <em>runtest</em> utility can be found in <code>GridConversion/CMakeLists.txt</code>, where it is used to run the parallel tests (which must use platform-specific parallel job spawning mechanisms), and other platform-specific, or complex behavior tests.</p>
<h3>Checking test results with <em>testresults</em>.</h3>
<p>The <em>testresults</em> utility is designed to extract a particular test result from a test results file with one test result per line. If the test's results are such that it has passed, then <em>testresults</em> returns with a zero exit code, and exits with a non-zero error code otherwise.</p>
<p>Examples of how to use the <em>testresults</em> utility can be found in <code>GridConversion/CMakeLists.txt</code>, where it is used to extract the results of all the tests.</p>
<h2><a class="anchor" id="putting_it_together"></a>
Putting it all together</h2>
<p>All together, the IRAD testing facilities provide an end-to-end framework for running, collecting, and reporting your project's tests and results to CMake in such a way that CMake's integrated testing facilty, CTest, can be leveraged to integrate the tests into the project's build system, automate the tests, and report the test results to a <em>testing</em> dashboard. The testing dashboard is a web-based facility which collects and reports test results the test histories. Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a> uses CDash for its testing dashboard.</p>
<p>The birds-eye view of the process for using IRAD's testing facilities with CMake/CTest goes like this:</p><ol type="1">
<li>Create a project-native testing object (PNTO) by inheriting from IRAD::Util::TestingObject.</li>
<li>Implement unit tests as member functions of the PNTO</li>
<li>Write a driver (or a set of drivers) that instantiates your testing object(s), and drives them to produce a IRAD::Util::TestResults object with the restults from the testing.</li>
<li>INCLUDE(CTEST) in your CMakeLists.txt file.</li>
<li>Invoke the test driver(s) with CMake's ADD_TEST() construct and store the results in a composite testing results file. If necessary use <em>runtest</em> to invoke the actual test(s).</li>
<li>If necessary, use <em>testresults</em> to extract the results of the tests from the composite testing results file and exit with a 0 return code for tests that pass, and a non-zero otherwise. This step is also accomplished with CMake's ADD_TEST().</li>
<li>Configure your project (i.e. run cmake), and then run the integrated tests with "make test".</li>
</ol>
<dl class="section note"><dt>Note</dt><dd>The reason it may or may not be necessary to use <em>runtest</em> and <em>testresults</em> in steps (5) and (6) is that your tests may be directly invoked by CMake's ADD_TEST <b>if</b> the test is a standalone executable that returns 0 if it succeeds, and non-zero otherwise.</dd></dl>
<h1><a class="anchor" id="irpt_testing"></a>
Testing in the Illinois Rocstar Project Template</h1>
<p>Direct examples of using IRAD Testing for several different kinds of tests are provided in the Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a> Project Template. The following sections summarize the main gist of each of these examples.</p>
<h2><a class="anchor" id="irpt_serial_tests"></a>
Serial Test Examples</h2>
<p>The Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a> Project Template has both a standalone serial program example, and several serial unit tests. The unit testing is described below, and discussion of the standalone test is deferred to a later section.</p>
<p>For the serial unit tests, the PNTO is called <a class="el" href="classGridConversion_1_1TestingObject.html" title="Project-specific testing object. ">GridConversion::TestingObject</a>. This object inherits from IRAD::Util::TestingObject as described in Step (1) above. The unit tests are in the <a class="el" href="classGridConversion_1_1TestingObject.html" title="Project-specific testing object. ">GridConversion::TestingObject</a>'s member methods as prescribed in Step (2). The simple tests and the code construct that they test are:</p><ul>
<li><a class="el" href="classGridConversion_1_1TestingObject.html#a14258b94075936cb7bfadbcfc9a37b87" title="Test for GridConversion::ExampleFunction. ">GridConversion::TestingObject::Test__ExampleFunction</a> tests <a class="el" href="namespaceGridConversion.html#a4cc78661909b0a33b6b886a4d4290997" title="Example function for GridConversion (this is a brief description). ">GridConversion::ExampleFunction</a></li>
<li><a class="el" href="classGridConversion_1_1TestingObject.html#a7928083cb5586c2b361e1d29a8dc2b54" title="Test for GridConversion::TrapezoidQuadrature. ">GridConversion::TestingObject::Test__TrapezoidQuadrature</a> tests <a class="el" href="namespaceGridConversion.html#a7ea1066c129172a0edf5647d8254e957" title="Integrates f with composite trapezoid rule. ">GridConversion::TrapezoidQuadrature</a></li>
<li><a class="el" href="classGridConversion_1_1TestingObject.html#a7de28a366b07117111ce7c1e9515a434" title="Test for GridConversion::MidPointQuadrature. ">GridConversion::TestingObject::Test__MidPointQuadrature</a> tests <a class="el" href="namespaceGridConversion.html#a94390a668cbb6637ea246c660d00d430" title="Integrates f with composite midpoint rule. ">GridConversion::MidPointQuadrature</a></li>
</ul>
<p>The <em>gridconversion_test</em> command-line driver executable, implemented by the <a class="el" href="namespaceGridConversion.html#a0449cb27fdca26e21a0be394f2ae38a2" title="Drives the GridConversion::TestObject. ">GridConversion::Test</a> function drives the <a class="el" href="classGridConversion_1_1TestingObject.html" title="Project-specific testing object. ">GridConversion::TestingObject</a> by instantiating it, and calling the <a class="el" href="classGridConversion_1_1TestingObject.html#af1f07f14b9af7708e4264bb38937eed2" title="Runs a test specified by name. ">GridConversion::TestingObject::RunTest</a> (if an explicit test name or list was given) or the <a class="el" href="classGridConversion_1_1TestingObject.html#a046f7ab06db0acf616b0d2bf3d3146aa" title="Runs all tests implemented by the GridConversion::TestingObject. ">GridConversion::TestingObject::Process</a> method to run all tests. This is Step(3).</p>
<p>Step (4) is trivial, and Step (5) is done with the following line from <code>GridConversion/CMakeLists.txt</code>:</p>
<blockquote class="doxtable">
<p>ADD_TEST(RunGridConversionTests ${EXECUTABLE_OUTPUT_PATH}/gridconversion_test -o gridconversion_testresults.txt) </p>
</blockquote>
<p>This runs all of the <a class="el" href="namespaceGridConversion.html" title="Project-specific namespace. ">GridConversion</a> tests implemented by the <a class="el" href="classGridConversion_1_1TestingObject.html" title="Project-specific testing object. ">GridConversion::TestingObject</a>, and stores the results in the file <code>gridconversion_testresults.txt</code>.</p>
<p>For Step (6), the <em>testresults</em> utility is used to extract the results of each of the tests from <code>gridconversion_testresults.txt</code> with the following lines from <code>GridConversion/CMakeLists.txt</code>:</p>
<blockquote class="doxtable">
<p>ADD_TEST(ExampleProgram:Works ${EXECUTABLE_OUTPUT_PATH}/testresults ExampleProgram:Works gridconversion_testresults.txt)<br />
ADD_TEST(ExampleFunction:Works ${EXECUTABLE_OUTPUT_PATH}/testresults ExampleFunction:Works gridconversion_testresults.txt)<br />
ADD_TEST(TrapezoidQuadrature:Runs ${EXECUTABLE_OUTPUT_PATH}/testresults TrapezoidQuadrature:Runs gridconversion_testresults.txt)<br />
ADD_TEST(TrapezoidQuadrature:Accurate ${EXECUTABLE_OUTPUT_PATH}/testresults TrapezoidQuadrature:Accurate gridconversion_testresults.txt)<br />
ADD_TEST(TrapezoidQuadrature:Order ${EXECUTABLE_OUTPUT_PATH}/testresults TrapezoidQuadrature:Order2 gridconversion_testresults.txt)<br />
ADD_TEST(MidPointQuadrature:Runs ${EXECUTABLE_OUTPUT_PATH}/testresults MidPointQuadrature:Runs gridconversion_testresults.txt)<br />
ADD_TEST(MidPointQuadrature:Accurate ${EXECUTABLE_OUTPUT_PATH}/testresults MidPointQuadrature:Accurate gridconversion_testresults.txt)<br />
ADD_TEST(MidPointQuadrature:Order ${EXECUTABLE_OUTPUT_PATH}/testresults MidPointQuadrature:Order2 gridconversion_testresults.txt)<br />
</p>
</blockquote>
<p>In Step (7), users configure <a class="el" href="namespaceGridConversion.html" title="Project-specific namespace. ">GridConversion</a> and invoke "make test" to run the tests and report the results to stdout.</p>
<h2><a class="anchor" id="irpt_parallel_tests"></a>
Parallel Test Examples</h2>
<p>The Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a> Project Template has both a standalone parallel application, <em>pepi</em>, and parallel unit tests. The <em>pepi</em> program computes <img class="formulaInl" alt="$\pi$" src="form_8.png"/> in parallel by doing parallel quadrature, and the unit tests test the parallel quadrature facility. Both will be discussed in this section.</p>
<p>In this test, the PNTO is called GridConversion::ParallelTestingObject. This object inherits from IRAD::Util::TestingObject as described in Step (1) above. The unit tests are in the GridConversion::ParallelTestingObject's member methods as prescribed in Step (2). The simple tests and the code construct that they test are:</p><ul>
<li>GridConversion::ParallelTestingObject::Test__ParallelTrapezoidQuadrature tests <a class="el" href="namespaceGridConversion.html#a7ea1066c129172a0edf5647d8254e957" title="Integrates f with composite trapezoid rule. ">GridConversion::TrapezoidQuadrature</a> in parallel</li>
<li>GridConversion::ParallelTestingObject::Test__ParallelMidPointQuadrature tests <a class="el" href="namespaceGridConversion.html#a94390a668cbb6637ea246c660d00d430" title="Integrates f with composite midpoint rule. ">GridConversion::MidPointQuadrature</a> in parallel</li>
</ul>
<p>The <em>gridconversion_parallel_test</em> command-line driver executable, implemented by the <a class="el" href="namespaceGridConversion.html#ad06df63ea71c2a866efb3ff9c90d7190" title="Drives the GridConversion::TestObject. ">GridConversion::ParallelTest</a> function drives the GridConversion::ParallelTestingObject by instantiating it, and calling the GridConversion::ParallelTestingObject::RunTest (if an explicit test name or list was given) or the GridConversion::ParallelTestingObject::Process method to run all tests. This is Step(3).</p>
<p>Step (4) is trivial, and Step (5) for this example is more complicated than that of the serial case. Since this is a parallel test, it must be spawned in parallel using something like <em>mpiexec</em> or <em>mpirun</em>. The parallel application spawning mechanism is platform-dependent, and even may need to be done through a batch queueing system.</p>
<p>Due to the platform-specific nature of executing parallel applications, Step (5) must be accomplished using the <em>runtest</em> utility. This is done in the following line from <code>GridConversion/CMakeLists.txt</code>:</p>
<blockquote class="doxtable">
<p>ADD_TEST(RunParallelPlatformTests ${EXECUTABLE_OUTPUT_PATH}/runtest -p ${PROJECT_SOURCE_DIR}/share/Platforms/parallel_platforms -o gridconversion_testresults.txt) </p>
</blockquote>
<p>This line gives the <code>GridConversion/share/Platforms/parallel_platforms</code> file as the <em>platform</em> argument to <em>runtest</em>. The parallel_platforms file is line-based and has the following format on each line: </p><blockquote class="doxtable">
<p>&lt;hostname&gt; &lt;path to platform-specific test list&gt; </p>
</blockquote>
<p>If not given on the command line, the <em>runtest</em> utility will determine the hostname and resolve the list of tests from this file. The platform-specific test list should list as many parallel testing scripts as one needs to do on the given platform. For example, see <code>GridConversion/share/Platforms/parallel_platforms</code>, and <code>GridConversion/share/Platforms/mercury_parallel.list</code>. You will see that the list includes two scripts that invoke the parallel tests:</p><ol type="1">
<li>mercury_parallel_test1.csh (runs the parallel unit test driver)</li>
<li>mercury_parallel_test2.csh (runs <em>pepi</em>)</li>
</ol>
<p>On Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a>'s mercury cluster, these tests must be conducted through the batch system. These testing scripts submit the tests to the batch system and report the results. These results are then fed into the <code>gridconversion_testsresults.txt</code> file.</p>
<p>Essentially, these scripts submit the jobs to mercury's queue, and then wait on the results before returning to the calling utility, <em>runtest</em>. For further details on how they do this, see <code>GridConversion/share/Platforms/mercury_parallel_test1.csh</code> and <code>GridConversion/share/Platforms/mercury_parallel_test2.csh</code>.</p>
<p>Once the <em>runtest</em> utility has returned, then the <code>gridconversion_testresults.txt</code> file has been updated with the results from the parallel tests, and, just like for the serial test Step (6), the <em>testresults</em> utility is used to extract the results of each of the tests from <code>gridconversion_testresults.txt</code> with the following lines from <code>GridConversion/CMakeLists.txt</code>:</p>
<blockquote class="doxtable">
<p>ADD_TEST(ParallelExample:Runs ${EXECUTABLE_OUTPUT_PATH}/testresults PEPI:Runs gridconversion_testresults.txt)<br />
ADD_TEST(ParallelExample:Works ${EXECUTABLE_OUTPUT_PATH}/testresults PEPI:Works gridconversion_testresults.txt)<br />
ADD_TEST(ParallelTrapezoidQuadrature:Runs ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelTrapezoidQuadrature:Runs gridconversion_testresults.txt)<br />
ADD_TEST(ParallelTrapezoidQuadrature:Accurate ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelTrapezoidQuadrature:Accurate gridconversion_testresults.txt)<br />
ADD_TEST(ParallelTrapezoidQuadrature:Order ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelTrapezoidQuadrature:Order2 gridconversion_testresults.txt)<br />
ADD_TEST(ParallelTrapezoidQuadrature:WeakScaling ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelTrapezoidQuadrature:WeakScaling gridconversion_testresults.txt)<br />
ADD_TEST(ParallelTrapezoidQuadrature:StrongScaling ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelTrapezoidQuadrature:StrongScaling gridconversion_testresults.txt)<br />
ADD_TEST(ParallelMidPointQuadrature:Runs ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelMidPointQuadrature:Runs gridconversion_testresults.txt)<br />
ADD_TEST(ParallelMidPointQuadrature:Accurate ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelMidPointQuadrature:Accurate gridconversion_testresults.txt)<br />
ADD_TEST(ParallelMidPointQuadrature:Order ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelMidPointQuadrature:Order2 gridconversion_testresults.txt)<br />
ADD_TEST(ParallelMidPointQuadrature:WeakScaling ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelMidPointQuadrature:WeakScaling gridconversion_testresults.txt)<br />
ADD_TEST(ParallelMidPointQuadrature:StrongScaling ${EXECUTABLE_OUTPUT_PATH}/testresults ParallelMidPointQuadrature:StrongScaling gridconversion_testresults.txt)<br />
</p>
</blockquote>
<p>In Step (7), users configure <a class="el" href="namespaceGridConversion.html" title="Project-specific namespace. ">GridConversion</a> and invoke "make test" to run the tests and report the results to stdout.</p>
<h2><a class="anchor" id="direct_tests"></a>
Direct Test Example</h2>
<p>The Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a> Project Template has one serial example program called <em>sep</em>. The <em>sep</em> program simply copies a file. It is a useful example because it can be directly invoked by CTest since <em>sep</em> returns 0 if it succeeds and 1 if not (e.g. the input file did not exist or something).</p>
<p>The following line from the <code>GridConversion/CMakeLists.txt</code> file invokes <em>sep</em> and evaluates whether it succeeded or failed (based solely on its return code):</p>
<blockquote class="doxtable">
<p>ADD_TEST(ExampleProgram:Runs ${EXECUTABLE_OUTPUT_PATH}/sep CMakeCache.txt) </p>
</blockquote>
<dl class="section note"><dt>Note</dt><dd>There is no output file, just a name for the test, and then the command it should run.</dd></dl>
<p>In order to evaluate whether <em>sep</em> actually did what it was told to do, we need a more complicated facility. In fact, this is done with <em>runtest</em> just like above. The following line from <code>GridConversion/CMakeLists.txt</code> runs a (number of) script(s) from a list. One of these scripts, namely <code>GridConversion/share/Testing/test_scripts/serial_tests.csh</code>, actually runs  and checks to make sure it copies a file correctly:</p>
<blockquote class="doxtable">
<p>ADD_TEST(RunTests ${EXECUTABLE_OUTPUT_PATH}/runtest -l ${PROJECT_SOURCE_DIR}/share/Testing/test_scripts/tests.list -o gridconversion_testresults.txt) </p>
</blockquote>
<h2><a class="anchor" id="direct_use"></a>
Reusing the Examples</h2>
<p>It is highly recommended to simply reuse the testing examples provided in the Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a> Project Template when creating your own tests that use this framework.</p>
<p>To reuse the example testing objects, the developer could just remove the existing test functions in the serial testing object <a class="el" href="classGridConversion_1_1TestingObject.html" title="Project-specific testing object. ">GridConversion::TestingObject</a> and the parallel testing object, GridConversion::ParallelTestingObject and then implement her own unit tests as member functions of those objects.</p>
<p>The corresponding constructs from the <code>CMakeLists.txt</code> file would need to be removed/added as well - and also the scripts invoking the tests, if necessary. The rest of the framework, including the test object drivers would still be valid and should continue to work without modification.</p>
<p>In order to create stand alone tests that utilize scripts users can copy the scripts located in testing/share/Testing/test_scripts and edit them for their needs. Additionally, they will need to follow the examples shown in testing/CMakeLists.txt for calling the standalone tests and add a call for their test. If users are creating a regression test or a "gold standard" test in which they wish to compare saved data to newly generated data a script and example command have been created to help. More information on this regression script is below.</p>
<h2><a class="anchor" id="gold_standard"></a>
Creating a "gold standard" test</h2>
<p>A script is provided to help users in creating a "gold standard" test. The idea behind a "gold standard" test is to have saved output from a previous run of the software, where the solution data or output is known to be accurate. The test will then run the newly compiled version of the software and compare the generated output against the saved data. Located in &lt;<b></b> &gt;/testing/share/Testing/test_scripts<b> is a script titled regression.csh. This script is set up to run a "gold standard" test after a few edits from the user. The places in the file that require editing are marked in the script and are explained below.</b></p>
<p><b>1) InputDir=_____ This entry should have the name of the input data directory, which should be created by the user and placed in testing/share/Testing/test_data. This directory should house all the necessary input data for running the user's executable. The regression script will copy this directory, navigate into it, and then execute the given command.</b></p>
<p><b>2) Outputs=_____ This entry should contain the names of the generated output files that the user wishes to compare with saved data.</b></p>
<p><b>3) OutputsCheck=_____ This entry should contain the names of the saved output data files to compare the new output files against. Note that the files are compared using the diff command. Also, the files in Outputs must have a one to one corresponence with the files in OutputsCheck.</b></p>
<p><b>4) TestName=_____ This entry should contain the name the user wishes to use for the test.</b></p>
<p><b>5) The command for running the user's executable should be entered at the appropriate place in the script (the loaction is indicated with a comment). The user can also add any other features to the script that may be specific to a test.</b></p>
<p><b>In order to run the test and check the results two lines need to be uncommented and one of them edited in testing/CMakeLists.txt. These two lines are present in the testing section and are indicated by RegressionTest as the test name. The first of these must be uncommented. This line calls the runtest executable which in turn calls the regression.csh script. The second instance with RegresionTest calls the testresult executable and verifies the output of the regression.csh script. This second line must be edited to have the name of the user's test used in 4) above. These names must match exactly or the test will indicate failure even if that is not the case. The location to place the test name is indicated in the file. The regression test should then be ready to run with the other tests.</b></p>
<p><b>Note that the regression.csh script utilizes an executable called diffdatafiles which is part of IRAD. This executable works like the Unix diff command but will also compare numbers within a given tolerance. Additionally it can be directed to ignore strings and only compare numbers. Using this command users can compare their numerical output to ensure that the answers are within a certain tolerance and ignore other aspects of a data file that might be unimportant like a time and date stamp. The default written into the script is to compare all output files using only the numbers and comparing within a tolerance of 1.0e-10. Therefore, diffdatafiles will read in each string from the two data files one at a time. If the strings are in fact numbers it will ensure that the two numbers from each file are within 1.0e-10 of one another (strings will not be compared). The usage for the diffdatafiles command is shown below so that users may change its arguments and runtime behavior if desired. </p><pre class="fragment">diffdatafiles [-hnb] [-v [level] -o &lt;filename&gt; -t [tolerance] ] &lt;file1&gt; &lt;file2&gt; 

    -h,--help
            Print out long version of help and exit.

    -v,--verblevel [level]
            Set the verbosity level. (default = 1)

    -o,--output &lt;filename&gt;
            Set the output file to &lt;filename&gt;. (default = stdout)

    -t,--tolerance [tolerance]
            Set the numerical tolerance for comparing numbers to &lt;tolerance&gt;.
            (The default for the tolerance is 1.0e-12.)
            (The default behavior without -t is to compare numbers as strings.)
            (This flag will automatically force the -b flag to be used.)

    -n,--numbers
            Only compare the numbers in the two files.
            (This flag will automatically force the -t flag to be used.)

    -b,--blank
            Ignore blank space between words (or numbers).

    &lt;file1&gt;
            First file to read in for comparison against file2.

    &lt;file2&gt;
            Second file to read in for comparison against file1.
</pre><p></b></p>
<p><b></b></p>
<h1><a class="anchor" id="autotesting_sec"></a>
Automated Testing</h1>
<p><b>The Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a> Project Template has a couple of utilities designed to assist in understanding and setting up automated testing through <a href="http://www.cmake.org/cmake/help/v2.8.8/ctest.html" title="CTest Manual">CTest</a>. A sort of "quickstart" set of steps for setting up automated testing is as follows:</p><ol type="1">
<li>Log in to Illinois <a class="el" href="namespaceRocstar.html">Rocstar</a>'s <a href="http://irweb/cdash">CDash</a> instance and create a new project for your project (if it does not already exist).</li>
<li>Make a directory from which to run your automated builds and tests (e.g. ~/AutomatedTesting).</li>
<li>Copy <code>GridConversion/share/Testing/test_scripts/ctest/{automated_test_script.cmake</code>,run_automated_tests,projects,modules} into your testing directory.</li>
<li>Edit the projects file to remove the examples and add the projects that you want to test.</li>
<li>Modify the environment module file in modules directory for your projects to reflect the desired build environment.</li>
<li>Edit the run_automated_tests script with your customizations.</li>
<li>Test the setup by executing: <blockquote class="doxtable">
<p><code></code>./run_automated_tests <code></code>./projects Experimental <code>~/AutomatedTesting</code> </p>
</blockquote>
</li>
<li>If everything works OK, then add a cron job to invoke <em>run_automated_tests</em> at your desired intervals and modes.</li>
</ol>
<p></b></p>
<p><b>For Step(1), log into <a href="http://irweb/cdash">CDash</a> and follow the steps to create a new project. Add yourself as an author, and anyone else that should know about the status of the automated builds/tests.</b></p>
<p><b>Steps(2) and (3) are obvious.</b></p>
<p><b>In Step(4), it should be noted that the projects file is processed line-by-line. Each line should indicate the parameters for a single build and test. The expected format for each functional line of projects file is as follows:</b></p>
<p><b></p><blockquote class="doxtable">
<p>&lt;Project Name&gt;|&lt;Branch Name&gt;|&lt;Branch Path&gt;|&lt;Repository Type&gt; </p>
</blockquote>
<p></b></p>
<p><b>Based on the line from the projects file, the testing utilities will automatically try to check out the following branch from either GIT or SVN with the following command:</b></p>
<p><b>svn: </p><blockquote class="doxtable">
<p><code>svn</code> <code>co</code> <code>&lt;Branch</code> Path&gt; <code>&lt;Project</code> Name&gt;_&lt;Branch Name&gt; </p>
</blockquote>
<p></b></p>
<p><b>git: </p><blockquote class="doxtable">
<p><code>git</code> <code>clone</code> <code>&lt;Branch</code> Path&gt; <code>&lt;Project</code> Name&gt;_&lt;Branch Name&gt; </p>
</blockquote>
<p></b></p>
<p><b>If the &lt;Project Name&gt;_&lt;Branch Name&gt; directory already exists, then CTest will simply update from SVN if there are changes in the repository. On fresh check-outs or updates, CTest will (re)configure and (re)build the project and run the tests. </b></p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Fri Jan 8 2016 02:27:47 for Rocstar by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.7 </li>
  </ul>
</div>
</body>
</html>
